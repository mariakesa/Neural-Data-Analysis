{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()\n",
    "\n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "import h5py\n",
    "\n",
    "stim_dat=loadmat('/media/maria/DATA1/Documents/ZebraFish/subject_1/data_full.mat')['data']['stim_full'][0][0]\n",
    "beh_dat=loadmat('/media/maria/DATA1/Documents/ZebraFish/subject_1/data_full.mat')['data']['Behavior_full'][0][0]\n",
    "hf = h5py.File('/media/maria/DATA1/Documents/ZebraFish/subject_1/TimeSeries.h5', 'r')\n",
    "neural_dat=np.array(hf['CellResp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10] - Iter[100/15], Total loss:0.0201, MSE loss:0.0198, Sparse loss:0.2977\n",
      "Epoch [1/10] - Iter[200/15], Total loss:0.0187, MSE loss:0.0184, Sparse loss:0.2373\n",
      "Epoch [1/10] - Iter[300/15], Total loss:0.0279, MSE loss:0.0270, Sparse loss:0.8246\n",
      "Epoch [1/10] - Iter[400/15], Total loss:0.0175, MSE loss:0.0173, Sparse loss:0.2793\n",
      "Train a epoch in 10 seconds\n",
      "\n",
      "Average MSE Loss on Test set: 0.0242\n",
      "Save Best Model in HISTORY\n",
      "\n",
      "Epoch [2/10] - Iter[100/15], Total loss:0.0207, MSE loss:0.0202, Sparse loss:0.5020\n",
      "Epoch [2/10] - Iter[200/15], Total loss:0.0209, MSE loss:0.0206, Sparse loss:0.3108\n",
      "Epoch [2/10] - Iter[300/15], Total loss:0.0196, MSE loss:0.0194, Sparse loss:0.2144\n",
      "Epoch [2/10] - Iter[400/15], Total loss:0.0191, MSE loss:0.0188, Sparse loss:0.2179\n",
      "Train a epoch in 11 seconds\n",
      "\n",
      "Average MSE Loss on Test set: 0.0240\n",
      "Save Best Model in HISTORY\n",
      "\n",
      "Epoch [3/10] - Iter[100/15], Total loss:0.0224, MSE loss:0.0222, Sparse loss:0.2125\n",
      "Epoch [3/10] - Iter[200/15], Total loss:0.0231, MSE loss:0.0227, Sparse loss:0.4258\n",
      "Epoch [3/10] - Iter[300/15], Total loss:0.0206, MSE loss:0.0203, Sparse loss:0.2658\n",
      "Epoch [3/10] - Iter[400/15], Total loss:0.0207, MSE loss:0.0204, Sparse loss:0.2526\n",
      "Train a epoch in 11 seconds\n",
      "\n",
      "Average MSE Loss on Test set: 0.0237\n",
      "Save Best Model in HISTORY\n",
      "\n",
      "Epoch [4/10] - Iter[100/15], Total loss:0.0198, MSE loss:0.0194, Sparse loss:0.3791\n",
      "Epoch [4/10] - Iter[200/15], Total loss:0.0212, MSE loss:0.0208, Sparse loss:0.4172\n",
      "Epoch [4/10] - Iter[300/15], Total loss:0.0239, MSE loss:0.0232, Sparse loss:0.6306\n",
      "Epoch [4/10] - Iter[400/15], Total loss:0.0207, MSE loss:0.0204, Sparse loss:0.2899\n",
      "Train a epoch in 11 seconds\n",
      "\n",
      "Average MSE Loss on Test set: 0.0236\n",
      "Save Best Model in HISTORY\n",
      "\n",
      "Epoch [5/10] - Iter[100/15], Total loss:0.0238, MSE loss:0.0233, Sparse loss:0.5202\n",
      "Epoch [5/10] - Iter[200/15], Total loss:0.0226, MSE loss:0.0220, Sparse loss:0.5872\n",
      "Epoch [5/10] - Iter[300/15], Total loss:0.0230, MSE loss:0.0227, Sparse loss:0.3019\n",
      "Epoch [5/10] - Iter[400/15], Total loss:0.0189, MSE loss:0.0185, Sparse loss:0.4570\n",
      "Train a epoch in 11 seconds\n",
      "\n",
      "Average MSE Loss on Test set: 0.0235\n",
      "Save Best Model in HISTORY\n",
      "\n",
      "Epoch [6/10] - Iter[100/15], Total loss:0.0248, MSE loss:0.0244, Sparse loss:0.4264\n",
      "Epoch [6/10] - Iter[200/15], Total loss:0.0189, MSE loss:0.0184, Sparse loss:0.4222\n",
      "Epoch [6/10] - Iter[300/15], Total loss:0.0206, MSE loss:0.0204, Sparse loss:0.2756\n",
      "Epoch [6/10] - Iter[400/15], Total loss:0.0189, MSE loss:0.0187, Sparse loss:0.1930\n",
      "Train a epoch in 12 seconds\n",
      "\n",
      "Average MSE Loss on Test set: 0.0235\n",
      "Save Best Model in HISTORY\n",
      "\n",
      "Epoch [7/10] - Iter[100/15], Total loss:0.0199, MSE loss:0.0197, Sparse loss:0.1909\n",
      "Epoch [7/10] - Iter[200/15], Total loss:0.0230, MSE loss:0.0227, Sparse loss:0.2474\n",
      "Epoch [7/10] - Iter[300/15], Total loss:0.0236, MSE loss:0.0233, Sparse loss:0.3644\n",
      "Epoch [7/10] - Iter[400/15], Total loss:0.0245, MSE loss:0.0239, Sparse loss:0.5154\n",
      "Train a epoch in 15 seconds\n",
      "\n",
      "Average MSE Loss on Test set: 0.0234\n",
      "Save Best Model in HISTORY\n",
      "\n",
      "Epoch [8/10] - Iter[100/15], Total loss:0.0205, MSE loss:0.0202, Sparse loss:0.3082\n",
      "Epoch [8/10] - Iter[200/15], Total loss:0.0206, MSE loss:0.0202, Sparse loss:0.3400\n",
      "Epoch [8/10] - Iter[300/15], Total loss:0.0184, MSE loss:0.0182, Sparse loss:0.1885\n",
      "Epoch [8/10] - Iter[400/15], Total loss:0.0235, MSE loss:0.0232, Sparse loss:0.2505\n",
      "Train a epoch in 15 seconds\n",
      "\n",
      "Average MSE Loss on Test set: 0.0233\n",
      "Save Best Model in HISTORY\n",
      "\n",
      "Epoch [9/10] - Iter[100/15], Total loss:0.0190, MSE loss:0.0188, Sparse loss:0.1839\n",
      "Epoch [9/10] - Iter[200/15], Total loss:0.0272, MSE loss:0.0270, Sparse loss:0.2522\n",
      "Epoch [9/10] - Iter[300/15], Total loss:0.0242, MSE loss:0.0239, Sparse loss:0.3348\n",
      "Epoch [9/10] - Iter[400/15], Total loss:0.0228, MSE loss:0.0225, Sparse loss:0.3076\n",
      "Train a epoch in 16 seconds\n",
      "\n",
      "Average MSE Loss on Test set: 0.0234\n",
      "Epoch [10/10] - Iter[100/15], Total loss:0.0207, MSE loss:0.0204, Sparse loss:0.2445\n",
      "Epoch [10/10] - Iter[200/15], Total loss:0.0194, MSE loss:0.0192, Sparse loss:0.2054\n",
      "Epoch [10/10] - Iter[300/15], Total loss:0.0193, MSE loss:0.0192, Sparse loss:0.1794\n",
      "Epoch [10/10] - Iter[400/15], Total loss:0.0431, MSE loss:0.0420, Sparse loss:1.0528\n",
      "Train a epoch in 19 seconds\n",
      "\n",
      "Average MSE Loss on Test set: 0.0234\n",
      "Trainig Complete with best validation loss 0.0233\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os, datetime\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "cuda = torch.cuda.is_available()\n",
    "device = torch.device('cuda:0' if cuda else 'cpu')\n",
    "\n",
    "class SparseAutoencoderL1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SparseAutoencoderL1, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(83205, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(32, 64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(128, 83205),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "def sparse_loss(autoencoder, images):\n",
    "    loss = 0\n",
    "    values = images\n",
    "    for i in range(3):\n",
    "        fc_layer = list(autoencoder.encoder.children())[2 * i]\n",
    "        relu = list(autoencoder.encoder.children())[2 * i + 1]\n",
    "        values = relu(fc_layer(values))\n",
    "        loss += torch.mean(torch.abs(values))\n",
    "    for i in range(2):\n",
    "        fc_layer = list(autoencoder.decoder.children())[2 * i]\n",
    "        relu = list(autoencoder.decoder.children())[2 * i + 1]\n",
    "        values = relu(fc_layer(values))\n",
    "        loss += torch.mean(torch.abs(values))\n",
    "    return loss\n",
    "\n",
    "def model_training(autoencoder, train_loader, epoch):\n",
    "    loss_metric = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(autoencoder.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "    autoencoder.train()\n",
    "    for i, data in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        images = data\n",
    "        images = Variable(images)\n",
    "        images = images.view(images.size(0), -1)\n",
    "        if cuda: images = images.to(device)\n",
    "        outputs = autoencoder(images)\n",
    "        mse_loss = loss_metric(outputs, images)\n",
    "        l1_loss = sparse_loss(autoencoder, images)\n",
    "        loss = mse_loss + SPARSE_REG * l1_loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (i + 1) % LOG_INTERVAL == 0:\n",
    "            print('Epoch [{}/{}] - Iter[{}/{}], Total loss:{:.4f}, MSE loss:{:.4f}, Sparse loss:{:.4f}'.format(\n",
    "                epoch + 1, EPOCHS, i + 1, len(train_loader.dataset) // BATCH_SIZE, loss.item(), mse_loss.item(), l1_loss.item()\n",
    "            ))\n",
    "\n",
    "def evaluation(autoencoder, test_loader):\n",
    "    total_loss = 0\n",
    "    loss_metric = nn.MSELoss()\n",
    "    autoencoder.eval()\n",
    "    for i, data in enumerate(test_loader):\n",
    "        images = data\n",
    "        images = Variable(images)\n",
    "        images = images.view(images.size(0), -1)\n",
    "        if cuda: images = images.to(device)\n",
    "        outputs = autoencoder(images)\n",
    "        loss = loss_metric(outputs, images)\n",
    "        total_loss += loss * len(images)\n",
    "    avg_loss = total_loss / len(test_loader.dataset)\n",
    "\n",
    "    print('\\nAverage MSE Loss on Test set: {:.4f}'.format(avg_loss))\n",
    "\n",
    "    global BEST_VAL\n",
    "    if TRAIN_SCRATCH and avg_loss < BEST_VAL:\n",
    "        BEST_VAL = avg_loss\n",
    "        #torch.save(autoencoder.state_dict(), './history/sparse_autoencoder_l1.pt')\n",
    "        print('Save Best Model in HISTORY\\n')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    EPOCHS = 10\n",
    "    BATCH_SIZE = 128\n",
    "    LEARNING_RATE = 1e-3\n",
    "    WEIGHT_DECAY = 1e-5\n",
    "    LOG_INTERVAL = 100\n",
    "    SPARSE_REG = 1e-3\n",
    "    TRAIN_SCRATCH = True        # whether to train a model from scratch\n",
    "    BEST_VAL = float('inf')\n",
    "    \n",
    "    autoencoder = SparseAutoencoderL1()\n",
    "    if cuda: autoencoder.to(device)\n",
    "    x_train,x_test,stim_train,stim_test=train_test_split(neural_dat,stim_dat.flatten(), test_size=0.33, random_state=42)\n",
    "    train_loader = DataLoader(x_train, batch_size=4,\n",
    "                        shuffle=True, num_workers=4)\n",
    "    test_loader = DataLoader(x_test, batch_size=1,\n",
    "                        shuffle=False, num_workers=4)\n",
    "    if TRAIN_SCRATCH:\n",
    "        # Training autoencoder from scratch\n",
    "        for epoch in range(EPOCHS):\n",
    "            starttime = datetime.datetime.now()\n",
    "            model_training(autoencoder, train_loader, epoch)\n",
    "            endtime = datetime.datetime.now()\n",
    "            print(f'Train a epoch in {(endtime - starttime).seconds} seconds')\n",
    "            \n",
    "            # evaluate on test set and save best model\n",
    "            evaluation(autoencoder, test_loader)\n",
    "            #utput=autoencoder(neural_dat.to_device(device))\n",
    "        print('Trainig Complete with best validation loss {:.4f}'.format(BEST_VAL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_loader = DataLoader(neural_dat, batch_size=1,\n",
    "                        shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2880, 1, 32)\n"
     ]
    }
   ],
   "source": [
    "lst=[]\n",
    "for i, data in enumerate(total_loader):\n",
    "        images = data\n",
    "        images = Variable(images)\n",
    "        images = images.view(images.size(0), -1)\n",
    "        if cuda: images = images.to(device)\n",
    "        outputs = autoencoder.encoder(images)\n",
    "        nps=outputs.cpu().detach().numpy()\n",
    "        lst.append(nps)\n",
    "lst=np.array(lst)\n",
    "print(lst.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "'c' argument has 1 elements, which is not acceptable for use with 'x' with size 2880, 'y' with size 2880.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36m_parse_scatter_color_args\u001b[0;34m(c, edgecolors, kwargs, xshape, yshape, get_next_color_func)\u001b[0m\n\u001b[1;32m   4283\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Then is 'c' acceptable as PathCollection facecolors?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4284\u001b[0;31m                 \u001b[0mcolors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmcolors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_rgba_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4285\u001b[0m                 \u001b[0mn_elem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/matplotlib/colors.py\u001b[0m in \u001b[0;36mto_rgba_array\u001b[0;34m(c, alpha)\u001b[0m\n\u001b[1;32m    293\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m         \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_rgba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/matplotlib/colors.py\u001b[0m in \u001b[0;36mto_rgba\u001b[0;34m(c, alpha)\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrgba\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Suppress exception chaining of cache lookup failure.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m         \u001b[0mrgba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_to_rgba_no_colorcycle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/matplotlib/colors.py\u001b[0m in \u001b[0;36m_to_rgba_no_colorcycle\u001b[0;34m(c, alpha)\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"RGBA sequence should have length 3 or 4\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: RGBA sequence should have length 3 or 4",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-9fa0c33e3c6c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpcs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpcs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpcs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstim_dat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mscatter\u001b[0;34m(x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, plotnonfinite, data, **kwargs)\u001b[0m\n\u001b[1;32m   2846\u001b[0m         \u001b[0mverts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medgecolors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0medgecolors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2847\u001b[0m         plotnonfinite=plotnonfinite, **({\"data\": data} if data is not\n\u001b[0;32m-> 2848\u001b[0;31m         None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2849\u001b[0m     \u001b[0msci\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__ret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2850\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m__ret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1597\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1598\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1599\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1601\u001b[0m         \u001b[0mbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mscatter\u001b[0;34m(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, plotnonfinite, **kwargs)\u001b[0m\n\u001b[1;32m   4451\u001b[0m             self._parse_scatter_color_args(\n\u001b[1;32m   4452\u001b[0m                 \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medgecolors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4453\u001b[0;31m                 get_next_color_func=self._get_patches_for_fill.get_next_color)\n\u001b[0m\u001b[1;32m   4454\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4455\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mplotnonfinite\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcolors\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36m_parse_scatter_color_args\u001b[0;34m(c, edgecolors, kwargs, xshape, yshape, get_next_color_func)\u001b[0m\n\u001b[1;32m   4295\u001b[0m                         \u001b[0;34m\"acceptable for use with 'x' with size {xs}, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4296\u001b[0m                         \u001b[0;34m\"'y' with size {ys}.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4297\u001b[0;31m                             \u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_elem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxsize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mysize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4298\u001b[0m                     )\n\u001b[1;32m   4299\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: 'c' argument has 1 elements, which is not acceptable for use with 'x' with size 2880, 'y' with size 2880."
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAANgElEQVR4nO3ccYjfd33H8efLxE6mtY7lBEmi7Vi6Gsqg7ug6hFnRjbR/JP8USaC4SmnArQ5mETocKvWvKUMQsmm2iVPQWv1DD4nkD1fpECO50lmalMAtOnNE6Fm7/lO0Znvvj99P77hcct/e/e4u3vv5gMDv+/t9fr9758PdM798f/f7paqQJG1/r9rqASRJm8PgS1ITBl+SmjD4ktSEwZekJgy+JDWxavCTfC7Jc0meucLtSfLpJHNJnk7ytsmPKUlaryHP8D8PHLjK7XcB+8Z/jgL/tP6xJEmTtmrwq+oJ4GdXWXII+EKNnALekORNkxpQkjQZOyfwGLuBC0uO58fX/WT5wiRHGf0vgNe+9rV/dMstt0zgy0tSH08++eRPq2pqLfedRPCzwnUrfl5DVR0HjgNMT0/X7OzsBL68JPWR5L/Xet9J/JbOPLB3yfEe4OIEHleSNEGTCP4M8N7xb+vcAbxYVZedzpEkba1VT+kk+TJwJ7AryTzwUeDVAFX1GeAEcDcwB7wEvG+jhpUkrd2qwa+qI6vcXsBfTWwiSdKG8J22ktSEwZekJgy+JDVh8CWpCYMvSU0YfElqwuBLUhMGX5KaMPiS1ITBl6QmDL4kNWHwJakJgy9JTRh8SWrC4EtSEwZfkpow+JLUhMGXpCYMviQ1YfAlqQmDL0lNGHxJasLgS1ITBl+SmjD4ktSEwZekJgy+JDVh8CWpCYMvSU0YfElqwuBLUhMGX5KaMPiS1ITBl6QmDL4kNTEo+EkOJDmXZC7Jwyvc/uYkjyd5KsnTSe6e/KiSpPVYNfhJdgDHgLuA/cCRJPuXLfs74LGqug04DPzjpAeVJK3PkGf4twNzVXW+ql4GHgUOLVtTwOvHl28ALk5uREnSJAwJ/m7gwpLj+fF1S30MuDfJPHAC+MBKD5TkaJLZJLMLCwtrGFeStFZDgp8Vrqtlx0eAz1fVHuBu4ItJLnvsqjpeVdNVNT01NfXKp5UkrdmQ4M8De5cc7+HyUzb3A48BVNX3gNcAuyYxoCRpMoYE/zSwL8lNSa5j9KLszLI1PwbeBZDkrYyC7zkbSbqGrBr8qroEPAicBJ5l9Ns4Z5I8kuTgeNlDwANJfgB8Gbivqpaf9pEkbaGdQxZV1QlGL8Yuve4jSy6fBd4+2dEkSZPkO20lqQmDL0lNGHxJasLgS1ITBl+SmjD4ktSEwZekJgy+JDVh8CWpCYMvSU0YfElqwuBLUhMGX5KaMPiS1ITBl6QmDL4kNWHwJakJgy9JTRh8SWrC4EtSEwZfkpow+JLUhMGXpCYMviQ1YfAlqQmDL0lNGHxJasLgS1ITBl+SmjD4ktSEwZekJgy+JDVh8CWpCYMvSU0MCn6SA0nOJZlL8vAV1rwnydkkZ5J8abJjSpLWa+dqC5LsAI4BfwbMA6eTzFTV2SVr9gF/C7y9ql5I8saNGliStDZDnuHfDsxV1fmqehl4FDi0bM0DwLGqegGgqp6b7JiSpPUaEvzdwIUlx/Pj65a6Gbg5yXeTnEpyYKUHSnI0yWyS2YWFhbVNLElakyHBzwrX1bLjncA+4E7gCPAvSd5w2Z2qjlfVdFVNT01NvdJZJUnrMCT488DeJcd7gIsrrPlGVf2yqn4InGP0D4Ak6RoxJPingX1JbkpyHXAYmFm25uvAOwGS7GJ0iuf8JAeVJK3PqsGvqkvAg8BJ4Fngsao6k+SRJAfHy04Czyc5CzwOfKiqnt+ooSVJr1yqlp+O3xzT09M1Ozu7JV9bkn5TJXmyqqbXcl/faStJTRh8SWrC4EtSEwZfkpow+JLUhMGXpCYMviQ1YfAlqQmDL0lNGHxJasLgS1ITBl+SmjD4ktSEwZekJgy+JDVh8CWpCYMvSU0YfElqwuBLUhMGX5KaMPiS1ITBl6QmDL4kNWHwJakJgy9JTRh8SWrC4EtSEwZfkpow+JLUhMGXpCYMviQ1YfAlqQmDL0lNGHxJasLgS1ITg4Kf5ECSc0nmkjx8lXX3JKkk05MbUZI0CasGP8kO4BhwF7AfOJJk/wrrrgf+Gvj+pIeUJK3fkGf4twNzVXW+ql4GHgUOrbDu48AngJ9PcD5J0oQMCf5u4MKS4/nxdb+W5DZgb1V982oPlORoktkkswsLC694WEnS2g0Jfla4rn59Y/Iq4FPAQ6s9UFUdr6rpqpqempoaPqUkad2GBH8e2LvkeA9wccnx9cCtwHeS/Ai4A5jxhVtJurYMCf5pYF+Sm5JcBxwGZn51Y1W9WFW7qurGqroROAUcrKrZDZlYkrQmqwa/qi4BDwIngWeBx6rqTJJHkhzc6AElSZOxc8iiqjoBnFh23UeusPbO9Y8lSZo032krSU0YfElqwuBLUhMGX5KaMPiS1ITBl6QmDL4kNWHwJakJgy9JTRh8SWrC4EtSEwZfkpow+JLUhMGXpCYMviQ1YfAlqQmDL0lNGHxJasLgS1ITBl+SmjD4ktSEwZekJgy+JDVh8CWpCYMvSU0YfElqwuBLUhMGX5KaMPiS1ITBl6QmDL4kNWHwJakJgy9JTRh8SWpiUPCTHEhyLslckodXuP2DSc4meTrJt5O8ZfKjSpLWY9XgJ9kBHAPuAvYDR5LsX7bsKWC6qv4Q+BrwiUkPKklanyHP8G8H5qrqfFW9DDwKHFq6oKoer6qXxoengD2THVOStF5Dgr8buLDkeH583ZXcD3xrpRuSHE0ym2R2YWFh+JSSpHUbEvyscF2tuDC5F5gGPrnS7VV1vKqmq2p6ampq+JSSpHXbOWDNPLB3yfEe4OLyRUneDXwYeEdV/WIy40mSJmXIM/zTwL4kNyW5DjgMzCxdkOQ24LPAwap6bvJjSpLWa9XgV9Ul4EHgJPAs8FhVnUnySJKD42WfBF4HfDXJfyaZucLDSZK2yJBTOlTVCeDEsus+suTyuyc8lyRpwnynrSQ1YfAlqQmDL0lNGHxJasLgS1ITBl+SmjD4ktSEwZekJgy+JDVh8CWpCYMvSU0YfElqwuBLUhMGX5KaMPiS1ITBl6QmDL4kNWHwJakJgy9JTRh8SWrC4EtSEwZfkpow+JLUhMGXpCYMviQ1YfAlqQmDL0lNGHxJasLgS1ITBl+SmjD4ktSEwZekJgy+JDVh8CWpCYMvSU0MCn6SA0nOJZlL8vAKt/9Wkq+Mb/9+khsnPagkaX1WDX6SHcAx4C5gP3Akyf5ly+4HXqiq3wc+Bfz9pAeVJK3PkGf4twNzVXW+ql4GHgUOLVtzCPi38eWvAe9KksmNKUlar50D1uwGLiw5ngf++EprqupSkheB3wV+unRRkqPA0fHhL5I8s5aht6FdLNurxtyLRe7FIvdi0R+s9Y5Dgr/SM/Vawxqq6jhwHCDJbFVND/j62557sci9WOReLHIvFiWZXet9h5zSmQf2LjneA1y80pokO4EbgJ+tdShJ0uQNCf5pYF+Sm5JcBxwGZpatmQH+Ynz5HuDfq+qyZ/iSpK2z6imd8Tn5B4GTwA7gc1V1JskjwGxVzQD/CnwxyRyjZ/aHB3zt4+uYe7txLxa5F4vci0XuxaI170V8Ii5JPfhOW0lqwuBLUhMbHnw/lmHRgL34YJKzSZ5O8u0kb9mKOTfDanuxZN09SSrJtv2VvCF7keQ94++NM0m+tNkzbpYBPyNvTvJ4kqfGPyd3b8WcGy3J55I8d6X3KmXk0+N9ejrJ2wY9cFVt2B9GL/L+F/B7wHXAD4D9y9b8JfCZ8eXDwFc2cqat+jNwL94J/Pb48vs778V43fXAE8ApYHqr597C74t9wFPA74yP37jVc2/hXhwH3j++vB/40VbPvUF78afA24BnrnD73cC3GL0H6g7g+0Med6Of4fuxDItW3YuqeryqXhofnmL0noftaMj3BcDHgU8AP9/M4TbZkL14ADhWVS8AVNVzmzzjZhmyFwW8fnz5Bi5/T9C2UFVPcPX3Mh0CvlAjp4A3JHnTao+70cFf6WMZdl9pTVVdAn71sQzbzZC9WOp+Rv+Cb0er7kWS24C9VfXNzRxsCwz5vrgZuDnJd5OcSnJg06bbXEP24mPAvUnmgRPABzZntGvOK+0JMOyjFdZjYh/LsA0M/nsmuReYBt6xoRNtnavuRZJXMfrU1fs2a6AtNOT7Yiej0zp3Mvpf338kubWq/meDZ9tsQ/biCPD5qvqHJH/C6P0/t1bV/238eNeUNXVzo5/h+7EMi4bsBUneDXwYOFhVv9ik2TbbantxPXAr8J0kP2J0jnJmm75wO/Rn5BtV9cuq+iFwjtE/ANvNkL24H3gMoKq+B7yG0QerdTOoJ8ttdPD9WIZFq+7F+DTGZxnFfruep4VV9qKqXqyqXVV1Y1XdyOj1jINVteYPjbqGDfkZ+TqjF/RJsovRKZ7zmzrl5hiyFz8G3gWQ5K2Mgr+wqVNeG2aA945/W+cO4MWq+slqd9rQUzq1cR/L8Btn4F58Engd8NXx69Y/rqqDWzb0Bhm4Fy0M3IuTwJ8nOQv8L/Chqnp+66beGAP34iHgn5P8DaNTGPdtxyeISb7M6BTervHrFR8FXg1QVZ9h9PrF3cAc8BLwvkGPuw33SpK0At9pK0lNGHxJasLgS1ITBl+SmjD4ktSEwZekJgy+JDXx/4aZaro1YsjCAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dat=lst.reshape(-1,32)\n",
    "from sklearn.decomposition import PCA\n",
    "pca=PCA(n_components=2)\n",
    "pcs=pca.fit_transform(dat)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(pcs[:,0],pcs[:,1],c=dat_sti)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
